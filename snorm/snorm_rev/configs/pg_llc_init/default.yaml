# DQN Minatar

experiment: PG-llc
device: cpu

game: LunarLanderContinuous-v2
env_no: 4

epochs: 12
train_step_cnt: 25000  # steps in the *parallel* env
valid_ep_cnt: 256  # some multiple of env_no

agent:
  name: PG
  nsteps: 32
  batch_size: 128
  mini_epochs: 1
  gamma: 0.99
  entropy_coeff: 0.0001
  normalize_advantage: no

estimator:
  name: ActorCritic
  args_:
    layer_dims: [64, 64]
    spectral: null

optim:
  name: "Adam"
  args_:
    lr: 0.001
    eps: 0.00001
