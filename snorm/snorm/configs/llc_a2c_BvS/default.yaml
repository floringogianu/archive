# DQN Minatar

experiment: A2C-LLc-BvS
device: cpu
# save: yes
# save_every_replay: False

epochs: 40
train_step_cnt: 25000  # these are "batched" steps
valid_ep_cnt: 256  # some multiple of batch size

game: LunarLanderContinuous-v2

agent:
  name: A2C
  batch_size: 8
  nsteps: 50
  gamma: 0.99
  entropy_coeff: 0.001

estimator:
  name: ActorCritic
  args_:
    layer_dims: [64, 64]
    spectral: null

optim:
  name: "Adam"
  args_:
    lr: 0.001
    eps: 0.00001
